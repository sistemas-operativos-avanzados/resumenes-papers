En multiprocesadores de memoria compartida, cada procesador puede direccionar memoria directamente la cual puede ser tambien direccionada por todos los otros procesadores. Este acceso uniforme requiere de algún método para asegurar exclusión mutua: la ejecución lógicamente atómica de las operaciones (secciones críticas) en una estructura de datos compartidos. La consistencia de la estructura de datos se garantiza al serializar las operaciones realizadas en ella.
Dado que la exclusión mutua a partir de sólo software es costosa, prácticamente todos los multiprocesadores de memoria compartida proveen alguna forma de soporte de hardware para realizar exclusión mutua para acceder a estructuras de datos compartidas. Este soporte usualmente consiste en instrucciones que leen y escriben atómicamente a una locación de memoria. Si las operaciones en la estructura de datos compartida son suficientemente simples, se pueden encapsular dentro de una sola instrucción atómica. La exclusión mutua tambén puede ser garantizada por hardware. Si un número de procesadores intentan actualizar simultáneamente la misma locación, cada uno espera su turno sin volver el control del vuelta al software. Un \textit{lock}(bloqueo) se necesario para las secciones críticas que toman más de una instrucción. Las instrucciones atómicas son usadas para arbitrar entre intentos simultáneos para adquirir el \textit{lock}, pero si el \textit{lock} está ocupado, la espera se hace en software. Cuando un \textit{lock} esta ocupado, el proceso de espera puede ya sea bloquear o rotar (\textit{spin} - espera activa) hasta que el \textit{lock} sea liberado. \textit{Spin-waiting} gasta mucho ciclos de procesador, es útil si la sección crítica es pequeña en donde el tiempo de espera es menor que el costo del bloqueo y reanudación del proceso, o si no otro trabajo está disponible.

\paragraph{\textnormal{\textbf{Range of Multiprocessor Architectures Considered}}}
Los \textit{Spinning processors} pueden retardar a los procesadores activos/ocupados en cualquier multiprocesador en donde la espera activa consuma ancho de banda en la comunicación. El rendimiento de la espera activa cambia a lo largo de varias dimensiones de arquitectura: cómo los procesadores esta conectados a la memoria, ya sea que cada procesador tenga un cache coherente privado gestionado por el hardware o no, y si lo tiene, el protocolo de coherencia. \textit{Common Hardware Support for Mutual Exclusion}: La mayoría de las arquitecturas soportan exclusión mutua al proveer instrucciones que leen, modifican y escriben en memoria de forma atómica. 

\underline{\textit{Multistage networks}} conectan múltiples procesadores con múltiples módulas de memoria. Solicitudes a memoria son reenviadas a través de una seria de \textit{switches} al módulo de memoria correcto. Cuando un valor se lee de memoria como parte de una instrucción atómica, cualquier copia(s) ``cacheada'' de la localización debe ser invalidada y accesos subsecuentes a ese módulo de memoria tienen que ser retrasadas mientras en nuevo valor es calculado. 

\underline{En multiprocesadores de un sólo bus}, el bus puede ser usado para arbitrar entre instrucciones atómicas simultáneas. Antes de iniciar una instrucción atómica, el procesador adquiere el bus y levanta una línea\footnote{La línea de bus atómica - atomic bus line}. Esta línea es retenida mientras el nuevo valor de memoria es obtenido para evitar que otras peticiones atómicas sean iniciadas, pero el bus puede ser liberado para permitir otras peticiones normales de memoria proceder. En sistemas que no ``cachean'' datos compartidos, la transacción de bus usada para adquirir el \textit{atomic bus line} puede ser superponer(\textit{overlapped}) con la petición de lectura para los datos o con la señal de invalidación de otras copias de cache. 

\underline{Invalidación basada en coherencia \textit{Write-back}} evita una transacción extra de bus para escribir los datos. El nuevo valor se almacena temporalmente en el cache del procesador. Cuando otro proceso necesita el valor, se obtiene el valor al mismo tiempo que se invalida la primer copia del procesador. En \underline{\textit{Distributed-write write-back coherence}}, la lectura inicial usualmente no se necesita. Esto porque copias en todos los ``caches'' son actualizadas en lugar de invalidadas cuando un procesador cambia un valor de memoria, el bloque de cache necesitado por la instrucción atómica se encontrará en el cache a menudo.

\paragraph{\textnormal{\textbf{The Performance of the Simple Approaches to Spin-Waiting}}}
El rendimiento cuando hay contención en el \textit{lock} depende de la minimización del ancho de banda de la comunicación usada por los \textit{spinning processors}, dado que esto puede causar que los procesadores hagan trabajo útil de forma lenta. El retraso que hay cuando un \textit{lock} es liberado y luego re-adquirido por un \textit{spinning processor} también debe ser minimizado, dado que ningún procesador estás ejecutando la sección crítica durante este tiempo. Inconveniente: entre más frecuentemente un procesador intenta adquirir un \textit{lock}, más rápido será adquirido pero también los otros procesadores estarán más interrumpidos. Latencia, el tiempo que le toma a un procesador en adquirir un \textit{lock} en la ausencia de contención es también un criterio importante en aplicaciones con bloqueos frecuentes. Un rendimiento pobre en contención puede evitar que una aplicación alcance su rendimiento máximo. Podría ser que no siempre sea posible modificar un programa para usar un número óptimo de procesadores. Un sistema operativo, tiene muy poco control sobre la tasa en la que los usuarios hacen llamadas al sistema. Durante cargas intensivas, \textit{locks} que normalmente no son un problema pueden convertirse en fuente de contención. 

\underline{\textit{Spin on Test-and-Set\footnote{TSL son las siglas de Test and set lock, una instrucción hardware utilizada por ciertos procesadores para facilitar la creación de semáforos y otras herramientas necesarias para la programación concurrente en computadoras.}}}. El algoritmo más simple de espera activa es que cada procesador ejecute repetidamente la instrucción \textit{test-and-set} hasta que tenga éxito en la adquisición. El rendimiento cae conforme el número de \textit{spinning processors} aumenta. Causas: (1) con el fin de liberar un \textit{lock}, el poseedor del \textit{lock} debe lidiar con \textit{spinning processors} por acceso exclusivo a la locación del \textit{lock}. (2) En arquitecturas en donde las peticiones de \textit{test-and-set} comparten el mismo bus como referencias de memoria normales, las peticiones de \textit{spinning processors} pueden retrasar acessos a otras locaciones por el possedor del \textit{lock} u otros procesos activos. (3) En arquitecturas \textit{multistage network} la espera activa puede causar un retraso en los accesos a los módulos de memoria que contienen la localización del \textit{lock} así como otros módulos. 

\underline{\textit{Spin on Read (Test-and-Test-and-Set)}}. Los \textit{spinning processors} hacen una lectura cíclica del valor del \textit{lock} y solamente cuando el \textit{lock} está libre, ejecutan una instrucción \textit{test-and-set}; esto elimina la necesidad de ejecutar \textit{test-and-set} repetitivamente mientras que el \textit{lock} está retenido. Mientras que el \textit{lock} está ocupado, el \textit{spinning} se hace en el cache sin consumir ciclos de red o bus. Cuando el \textit{lock} es liberado, cada copia es actualizada a un nuevo valor o invalidada, causando un \textit{read miss} el cual obtiene el nuevo valor. El procesador que espera ve el cambio en el estado y realiza un \textit{test-and-set}. Si alguien adquiere el \textit{lock} en el interim, el procesador puede reanudar el \textit{spinning} en su cache. 

\underline{\textit{Reasons for the Poor Performance os Spin on Read:}} razones por las cuáles el rendimiento de \textit{spinning} en memoria puede ser peor que el esperado: (1) Existe una separación entre la detección que el \textit{lock} ha sido liberado e intentar adquirirlo por medio de la instrucción \textit{test-and-set}. (2) Copias de cache del \textit{lock} son invalidadas por la instrucción \textit{test-and-set} incluso si el valor no es cambiado. (3) Coherencia de cache basada en invalidación requiere de $\mathcal{O}(P)$ ciclos de bus o red para emitir un valor a $P$ procesadores en espera. \underline{\textit{Measurement Results:}} el rendimiento se degrada conforme los procesadores giran(\textit{spin}) en \textit{test-and-set}. Conforme la sección crítica se convierte en un cuello de botella, el número promedio de \textit{spinning processors} aumenta, lo que hace significativamente más lento al procesador el ejecutar la sección crítica. Como resultado el rendimiento tope nunca es alcanzado.

\paragraph{\textnormal{\textbf{New Software Alternatives}}}
\underline{\textit{Delay Alternatives:}} (1) \textit{Delay after Spinning Processor Notices Lock has been Released:} se puede reducir el número \textit{test-and-set} fallidos en una lectura al insertar un retraso entre el momento en el que el procesador lee que el \textit{lock} fue liberado y cuando se compromete a intentar el \textit{test-and-set}. Si otro procesador adquiere el \textit{lock} durante este retraso, entonces el procesador puede reanundar el \textit{spinning}, sino entonces el procesador puede intentar el \textit{test-and-set} con mayor probabilidad que el \textit{lock} será adquirido. De esta forma el numero de \textit{test-and-set} fallidos y por lo tanto invalidaciones, pueden ser reducidas. A cada procesador se le puede asignar estáticamente una cantidad de tiempo de retraso que va de $0$ a $P - 1$ en donde $P$ es el número de procesadores. El \textit{spinning processor} con el menor retraso asignado revisa el \textit{lock}, ve si está libre y lo adquiere. Procesadores con tiempos de retraso más largos   caducan, ven que el \textit{lock} está ocupado y reanundan el \textit{spinning}. La asignación estática de retrasos se puede asegurar de que al menos un procesador caduque en cualquier instante. (2) \textit{Delay Between Each Memory Reference:} un enfoque alternativo es reducir el costo de la espera activa es insertar un retraso entre cada referencia de memoria. Esto puede ser usado en arquitecturas sin coherencia de cache o con invalidación basada en coherencia para limitar el ancho de banda de la comunicación que consumen los \textit{spinning processors}. 

\underline{\textit{Queing in Shared Memory:}} Usar la memoria compartida para almacenar el estado de la actividad de los \textit{spinning procesors} podría resultar más costoso puesto que se necesitarían dos instrucciones atómicas extra por sección crítica. Se propone un nuevo método de cola de espera (queueing) para procesadores en espera activa que solamente requiere una instrucción atómica por cada ejecución de una sección crítica. Cada procesador que arriba realiza un \textit{read-and-increment} atómico para obtener un número único de secuencia. Cuando un procesador finaliza el \textit{lock}, le asigna el procesador el número de secuencia siguien más alto; ahora el procesador es dueño del \textit{lock}. Dado que los procesadores están secuenciados, no se necesitan instrucciones \textit{read-modify-write} atómicas para pasarle el control al \textit{lock}.

\paragraph{\textnormal{\textbf{Hardware Solutions}}}
Tal y como en las soluciones de software, las soluciones de hardware también tienen sus pros y contras. Por ejemplo, el mejor mecanismo de coherencia de cache para \textit{spin locks} puede no ser el mejor para referencias de memoria normales. 

\underline{\textit{Multistage Interconnection Network Multiprocessors:}} combinación de redes, por medio de acceso paralelo a un localización de memoria, puede mejorar el rendimiento del \textit{spinning} directo en \textit{test-and-set}. Peticiones al mismo lugar que arriban al mismo \textit{switch} de red se combinan y reenvían como una sola petición; el resultado es el mismo como si dos peticiones fueran hechas de forma secuencial al módulo de memoria. Colas de espera de hardware en el módulo de memoria, como en colas de espera en software, pueden eliminar el \textit{polling} a través de la red -- también pueden hacer más rápido el paso de control de un \textit{lock}. Para esto, los procesadores deben emitir instrucciones ``enter'' y ``exit'' explícitos en secciones críticas al módulo de memoria, el cual podría mantener colas de los procesadores esperando para cada \textit{lock}. Cuando una solicitud ``enter'' del procesador retorna, se tiene el \textit{lock}; no es necesario hacer \textit{polling} en la red. En sistemas con coherencia de cache y colas de espera de software, el procesador que libera el \textit{lock} le notifica al siguiente por medio de la escritura de esta bandera (\textit{flag}). Una invalidación seguida de un \textit{read miss} es necesaria antes de que el \textit{spinning processor} puede iniciar la ejecución de la sección crítica. Al manejar de forma especial las solicitudes de sección crítica, la cola de espera en hardware elimina una viaje(ida y vuelta) en la red para pasar el control del \textit{lock}. La latencia de \textit{lock} es probable que sea mejor en hardware que con colas de espera en software. Las colas de espera en hardware incrementan la complejidad en el módulo de memoria, reducen el número de instrucciones necesarias para adquirir el \textit{lock}. 

\underline{\textit{Single Bus Multiprocessors:}} (1) \textit{Read Broadcast:} puede eliminar solicitudes duplicadas de \textit{read miss}. El controlador de cache de cada procesador monitorea el bus; si se produce una lectura correspondiente a un bloque inválido en su cache se toman los datos del bus y se establece el bloque como válido. Asi que, cuando las copias de cache de los \textit{spinning processors} están invalidadas, la primera lectura va a llenar todos los caches. (2) Por medio de un manejo especial de las solicitudes \textit{test-and-set} en el cache y en el bus de los controladores, se puede eliminar la necesidad de que \textit{test-and-set} fallidos usen el bus. De esta forma, un procesador puede rotar(\textit{spin}) en \textit{test-and-set}, adquirir el \textit{lock} lo más rápidamente cuando está libre, sin consumir ancho de banda del bus cuando el \textit{lock} está ocupado. Al proveer este manejo especial de instrucciones \textit{test-and-set}, no se incrementa el bus o los ciclos de cache, el rendimiento es mejor que con software \textit{backoff}\footnote{Reducir el uso de otros otros recursos de sistemas.} o colas de espera.  

\section{¿Cuál es el problema que plantea el \textit{paper}?}
Este artículo examina la siguiente pregunta: dado un hardware que soporta instrucciones atómicas, existen algoritmos eficientes para software de espera activa (\textit{sping waiting}), o hay más tipos más complejo de soporte de hardware necesarios para el rendimiento? 

\section{¿Por qué el problema es interesante o importante?}
La mayoría de arquitecturas de multiprocesadores proveen soporte de hardware para excluir mutuamente accesos a estruturas de datos compartidas. Este soporte usualmente consiste de instrucciones que leen y luego escriben en una localización de memoria de forma atómica. Estas instrucciones atómicas son utilizadas para manipular bloqueos (\textit{locks}): cuando un procesador está accediendo una estructura de datos, su \textit{lock} esta ocupado y otros procesadores que necesiten acceso tienen que esperar. Para secciones críticas pequeñas, esperar activamente para que un \textit{lock} sea liberado es más eficiente que renunciar al procesador para hacer otro trabajo. Desafortunadamente, la espera activa puede retrasar otros procesadores al consumir ancho de banda de comunicación. 

\section{¿Qué otras soluciones se han intentado para resolver este problema?}
Muchos multiprocesadores de memoria compartida han sido diseñados en el pasado reciente: el \textit{Sequent Simmetry}, Alliant FX, BBN Butterfly están entre los que han tenido mayor éxito comercial. En investigación: DEC SRC Firefly, Illinois Cedar, IBM RP3 y el Wisconsin Multicube. Todos los procesadores anteriores soportan instrucciones atómicas, aunque algunos, como el Multicube también provee otros mecanismos.

     
\section{¿Cuál es la solución propuesta por los autores?}
Se propone un nuevo método para poner en una cola de espera explítica los \textit{spinning processors}. Conforme los procesadores arriban al \textit{lock}, cada uno de ellos adquiere un número único de secuencia especificando el orden en que ellos ejecutarán la sección crítica. Cuado el bloqueo es liberado, el control puede ser pasado directamente al siguiente procesador en la línea sin mayor sincronización y con efectos mínimos en otros procesadores. También se examina el rendimiento de varias soluciones de hardware. Se propone una adición a protocolos de \textit{snoopy cache} para explotar la semántica de las solicitudes \textit{spin lock} para obtener mejor rendimiento. 

\section{¿Qué tan exitosa es esta solución?} 
Para multiprocesadores sin soporte especial para espera activa más allá de implementar instrucciones atómicas, se mostró que una cola de espera en software y una variante de \textit{Ethernet backoff} tiene buen rendimiento incluso para grandes número de \textit{spinning processors}. Debido a que es simple, \textit{backoff} tiene mejor rendimiento cuando no hay contención para el \textit{lock}. Una cola de espera, por medio de paralelización de la transferencia del \textit{lock}(\textit{lock handoff}) rinde mejor cuando hay procesadores en espera.

También se mostró que el rendimiento puede ser mejorado al manejar especialmente las solicitudes de \textit{spin lock}. En multiprocesadores con \textit{multistage interconnection networks}, colas en espera explícitas en hardware de procesadores en espera activa, pueden reducir el tiempo de para pasar el control del \textit{lock} a un procesador en espera.


