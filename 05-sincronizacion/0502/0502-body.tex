En multiprocesadores de memoria compartida, cada procesador puede direccionar memoria directamente la cual puede ser tambien direccionada por todos los otros procesadores. Este acceso uniforme requiere de algún método para asegurar exclusión mutua: la ejecución lógicamente atómica de las operaciones (secciones críticas) en una estructura de datos compartidos. La consistencia de la estructura de datos se garantiza al serializar las operaciones realizadas en ella.
Dado que la exclusión mutua a partir de sólo software es costosa, prácticamente todos los multiprocesadores de memoria compartida proveen alguna forma de soporte de hardware para realizar exclusión mutua para acceder a estructuras de datos compartidas. Este soporte usualmente consiste en instrucciones que leen y escriben atómicamente a una locación de memoria. Si las operaciones en la estructura de datos compartida son suficientemente simples, se pueden encapsular dentro de una sola instrucción atómica. La exclusión mutua tambén puede ser garantizada por hardware. Si un número de procesadores intentan actualizar simultáneamente la misma locación, cada uno espera su turno sin volver el control del vuelta al software. Un \textit{lock}(bloqueo) se necesario para las secciones críticas que toman más de una instrucción. Las instrucciones atómicas son usadas para arbitrar entre intentos simultáneos para adquirir el \textit{lock}, pero si el \textit{lock} está ocupado, la espera se hace en el software. Cuando un \textit{lock} esta ocupado, el proceso de espera puede ya sea bloquear o rotar (\textit{spin} - espera activa) hasta que el \textit{lock} sea liberado. \textit{Spin-waiting} gasta mucho ciclos de procesador, es útil si la sección crítica es pequeña en donde el tiempo de espera es menor que el costo del bloqueo y reanudación del proceso, o si no otro trabajo está disponible.

\paragraph{\textnormal{\textbf{Range of Multiprocessor Architectures Considered}}}
Los \textit{Spinning processors} pueden retardar a los procesadores activos/ocupados en cualquier multiprocesador en donde la espera activa consuma ancho de banda en la comunicación. El rendimiento de la espera activa cambia a lo largo de varias dimensiones de arquitectura: cómo los procesadores esta conectados a la memoria, ya sea que cada procesador tenga un cache coherente privado gestionado por el hardware o no, y si lo tiene, el protocolo de coherencia. \textit{Common Hardware Support for Mutual Exclusion}: La mayoría de las arquitecturas soportan exclusión mutua al proveer instrucciones que leen, modifican y escriben en memoria de forma atómica. \underline{\textit{Multistage networks}} conectan múltiples procesadores con múltiples módulas de memoria. Solicitudes a memoria son reenviadas a través de una seria de \textit{switches} al módulo de memoria correcto. Cuando un valor se lee de memoria como parte de una instrucción atómica, cualquier copia(s) ``cacheada'' de la localización debe ser invalidada y accesos subsecuentes a ese módulo de memoria tienen que ser retrasadas mientras en nuevo valor es calculado. \underline{En multiprocesadores de un sólo bus}, el bus puede ser usado para arbitrar entre instrucciones atómicas simultáneas. Antes de iniciar una instrucción atómica, el procesador adquiere el bus y levanta una línea\footnote{La línea de bus atómica - atomic bus line}. Esta línea es retenida mientras el nuevo valor de memoria es obtenido para evitar que otras peticiones atómicas sean iniciadas, pero el bus puede ser liberado para permitir otras peticiones normales de memoria proceder. En sistemas que no ``cachean'' datos compartidos, la transacción de bus usada para adquirir el \textit{atomic bus line} puede ser superponer(\textit{overlapped}) con la petición de lectura para los datos o con la señal de invalidación de otras copias de cache. \underline{Invalidación basada en coherencia \textit{Write-back}} evita una transacción extra de bus para escribir los datos. El nuevo valor se almacena temporalmente en el cache del procesador. Cuando otro proceso necesita el valor, se obtiene el valor al mismo tiempo que se invalida la primer copia del procesador. En \underline{\textit{Distributed-write write-back coherence}}, la lectura inicial usualmente no se necesita. Esto porque copias en todos los ``caches'' son actualizadas en lugar de invalidadas cuando un procesador cambia un valor de memoria, el bloque de cache necesitado por la instrucción atómica se encontrará en el cache a menudo.

\paragraph{\textnormal{\textbf{The Performance of the Simple Approaches to Spin-Waiting}}}
El rendimiento cuando hay contención en el \textit{lock} depende de la minimización del ancho de banda de la comunicación usada por los \textit{spinning processors}, dado que esto puede causar que los procesadores hagan trabajo útil de forma lenta. El retraso que hay cuando un \textit{lock} es liberado y luego re-adquirido por un \textit{spinning processor} también debe ser minimizado, dado que ningún procesador estás ejecutando la sección crítica durante este tiempo. Inconveniente: entre más frecuentemente un procesador intenta adquirir un \textit{lock}, más rápido será adquirido pero también los otros procesadores estarán más interrumpidos. Latencia, el tiempo que le toma a un procesador en adquirir un \textit{lock} en la ausencia de contención es también un criterio importante en aplicaciones con bloqueos frecuentes. Un rendimiento pobre en contención puede evitar que una aplicación alcance su rendimiento máximo. Podría ser que no siempre sea posible modificar un programa para usar un número óptimo de procesadores. Un sistema operativo, tiene muy poco control sobre la tasa en la que los usuarios hacen llamadas al sistema. Durante cargas intensivas, \textit{locks} que normalmente no son un problema pueden convertirse en fuente de contención. \underline{\textit{Spin on Test-and-Set\footnote{TSL son las siglas de Test and set lock, una instrucción hardware utilizada por ciertos procesadores para facilitar la creación de semáforos y otras herramientas necesarias para la programación concurrente en computadoras.}}}. El algoritmo más simple de espera activa es que cada procesador ejecute repetidamente la instrucción \textit{test-and-set} hasta que tenga éxito en la adquisición. El rendimiento cae conforme el número de \textit{spinning processors} aumenta. Causas: (1) con el fin de liberar un \textit{lock}, el poseedor del \textit{lock} debe lidiar con \textit{spinning processors} por acceso exclusivo a la locación del \textit{lock}. (2) En arquitecturas en donde las peticiones de \textit{test-and-set} comparten el mismo bus como referencias de memoria normales, las peticiones de \textit{spinning processors} pueden retrasar acessos a otras locaciones por el possedor del \textit{lock} u otros procesos activos. (3) En arquitecturas \textit{multistage network} la espera activa puede causar un retraso en los accesos a los módulos de memoria que contienen la localización del \textit{lock} así como otros módulos. \underline{\textit{Spin on Read (Test-and-Test-and-Set)}}. Los \textit{spinning processors} hacen una lectura cíclica del valor del \textit{lock} y solamente cuando el \textit{lock} está libre, ejecutan una instrucción \textit{test-and-set}; esto elimina la necesidad de ejecutar \textit{test-and-set} repetitivamente mientras que el \textit{lock} está retenido. Mientras que el \textit{lock} está ocupado, el \textit{spinning} se hace en el cache sin consumir ciclos de red o bus. Cuando el \textit{lock} es liberado, cada copia es actualizada a un nuevo valor o invalidada, causando un \textit{read miss} el cual obtiene el nuevo valor. El procesador que espera ve el cambio en el estado y realiza un \textit{test-and-set}. Si alguien adquiere el \textit{lock} en el interim, el procesador puede reanudar el \textit{spinning} en su cache. \underline{\textit{Reasons for the Poor Performance os Spin on Read:}} razones por las cuáles el rendimiento de \textit{spinning} en memoria puede ser peor que el esperado: (1) Existe una separación entre la detección que el \textit{lock} ha sido liberado e intentar adquirirlo por medio de la instrucción \textit{test-and-set}. (2) Copias de cache del \textit{lock} son invalidadas por la instrucción \textit{test-and-set} incluso si el valor no es cambiado. (3) Coherencia de cache basada en invalidación requiere de $\mathcal{O}(P)$ ciclos de bus o red para emitir un valor a $P$ procesadores en espera. \underline{\textit{Measurement Results:}} el rendimiento se degrada conforme los procesadores giran(\textit{spin}) en \textit{test-and-set}. Conforme la sección crítica se convierte en un cuello de botella, el número promedio de \textit{spinning processors} aumenta, lo que hace significativamente más lento al procesador el ejecutar la sección crítica. Como resultado el rendimiento tope nunca es alcanzado.

\paragraph{\textnormal{\textbf{New Software Alternatives}}}
\underline{\textit{Delay Alternatives:}} (1) \textit{Delay after Spinning Processor Notices Lock has been Released:} se puede reducir el número \textit{test-and-set} fallidos en una lectura al insertar un retraso entre el momento en el que el procesador lee que el \textit{lock} fue liberado y cuando se compromete a intentar el \textit{test-and-set}. Si otro procesador adquiere el \textit{lock} durante este retraso, entonces el procesador puede reanundar el \textit{spinning}, sino entonces el procesador puede intentar el \textit{test-and-set} con mayor probabilidad que el \textit{lock} será adquirido. De esta forma el numero de \textit{test-and-set} fallidos y por lo tanto invalidaciones, pueden ser reducidas. A cada procesador se le puede asignar estáticamente una cantidad de tiempo de retraso que va de $0$ a $P - 1$ en donde $P$ es el número de procesadores. El \textit{spinning processor} con el menor retraso asignado revisa el \textit{lock}, ve si está libre y lo adquiere. Procesadores con tiempos de retraso más largos   caducan, ven que el \textit{lock} está ocupado y reanundan el \textit{spinning}. La asignación estática de retrasos se puede asegurar de que al menos un procesador caduque en cualquier instante.

\section{¿Cuál es el problema que plantea el \textit{paper}?}

\section{¿Por qué el problema es interesante o importante?}

\section{¿Qué otras soluciones se han intentado para resolver este problema?}
     
\section{¿Cuál es la solución propuesta por los autores?}

\section{¿Qué tan exitosa es esta solución?} 