Una computadora de control de proceso realiza una o más funciones de control y monitoreo. Apuntar con una antena y registrar si una nave espacial está en orbita is una de los ejemplos de dichas funciones. Cada función que se realiza está asociada con un conjunto de una o más tareas. Algunas de estas tareas son ejecutadas en respuesta a eventos en un equipo que es controlado o monitoreado por una computadora. Las restantes son ejecutadas en respuesta a eventos de otras tareas. Ninguna de estas tareas puede ser ejecutadas antes que el evento que se solicitado ocurra. Cada una de las tareas deben ser completadas antes que un tiempo fijo hay transcurrido luego de la solicitud que se les hizo. Servicio dentro de este rango de tiempo debe ser garantizado, lo que cataloga el ambiente como \emph{hard-real-time} en contraste con \emph{soft-real-time} en donde una distribución estadística de los tiempos de respuesta es aceptable.

\paragraph{\textnormal{\textbf{The Environment}}} Para obtener algun resultado analítico acerca del comportamiento del programa en un ambiente \emph{hard-real-time}, ciertas suposiciones deben ser hechas acerca del ambiente. No todas estas suposiciones son absolutamente necesarias: \textbf{(A1)} Las solicitudes para todas las tareas para las cuales existen \emph{hard deadlines} son periódicas, con un intervalo constante entre las solicitudes. \textbf{(A2)} Los \emph{Deadlines} consisten solamente de restricciones en la capacidad de ejecución -- por ejemplo, cada tarea tiene que ser completada antes que la nueva solicitud para ella ocurra. \textbf{(A3)} Las tareas son independientes en el sentido de que las solicitudes para una determinada tarea no dependen de la iniciación o la finalización de solicitudes para otras tareas. \textbf{(A4)} El tiempo de ejecución para cada tarea es constante para esa tarea y no varía con el tiempo. Aquí, el tiempo de ejecución se refiere al tiempo que toma al procesador ejecutar una tarea sin interrupción. \textbf{(A5)} Cualquier tarea no periódica en el sistema es especial; son rutinas de inicialización o recuperación de fallos; desplazan a las tareas periódicas mientras ellas mismas corren y no tienen \emph{dealines} fuertes(\emph{hard}). Un algoritmo de \emph{scheduling} es un conjunto de reglas que determinan la tarea a ser ejecutada en un momento en particular. Los algoritmos del artículo son apropiativos y basados en prioridades. Un algoritmo de \emph{scheduling} se dice que es \textbf{estático} (o algoritmo de \emph{scheduling} de prioridades fijas.) si las prioridades son asignadas a las tareas una vez y no cambian. Un algoritmo de \emph{scheduling} se dice \textbf{dinámico} si las prioridades de las tareas pueden cambiar de solicitud en solicitud. Un algoritmo de \emph{scheduling} se dice \emph{mixed scheduling algorithm} si las prioridades de algunas de las tareas son fijas mientras que las prioridades restantes varían de solicitud en solicitud.

\paragraph{\textnormal{\textbf{A Fixed Priority Scheduling Algorithm}}}
El \emph{deadline} de una solicitud para una tarea se define como el tiempo de la siguiente solicitud para la misma tarea. Para un conjunto de tareas planificadas por un algún algoritmo de \emph{scheduling}, se deice que un \emph{overflow} ocurre en el tiempo $t$ si $t$ es el \emph{deadline} de una solicitud que no se cumplió. Para un dado conjunto de tareas, un algoritmo de \emph{scheduling} es factible si las tareas son planificadas de tal forma que no ocurra ningún \emph{overflow}. El tiempo de respuesta de una solicitud para cierta tarea se define como el tiempo que hay entre la solicitud y el final de la respuesta para esta solicitud.  Un \emph{critical instant} para una tarea se define como un instante en donde una solucitud para dicha tarea tendrá el tiempo de respuesta más largo. Una \emph{critical time zone} para una tarea es el intervalo entre un \emph{critical instant} y el fin de la respuesta de la solicitud correspondiente de una tarea. \underline{Teorema 1:} Un \emph{critical-instant} para cualquier tarea ocurre cuando la tarea es solicitada simultáneamente con solicitudes para todas las tareas de alta prioridad. \underline{Teorema 2:} Si una asignación de prioridad factible existe para algún conjunto de tareas, la asignación de prioridad \emph{rate-monotonic} es factible para ese conjunto de tareas.

\paragraph{\textnormal{\textbf{Achievable Processor Utilization}}}
El factor de utilización del procesador se define como la fracción del tiempo de procesador gastado en la ejecución del conjunto de tareas. En otras palabras, el factor de utilizacio4n es igual a uno menos la fracción de tiempo de procesador inactivo. Dado que $C_i/T_i$ es la fracción de tiempo de procesador gastado en ejecutar la tarea $\tau$, para $m$ el factor de utilización es: $$U = \sum_{i = 1}^{m} (C_i/T_i)$$. Aunque el factor de utilización puede ser mejorado incrementando los valores de los $C_i$'s o decrementando los valores de los $T_i$'s es limitado superiormente por los requerimientos que todas las tareas satisfagan sus \emph{deadlines} en sus \emph{critical instants}. Correspondiente a una asignación de prioridad, un conjunto de tareas se dice que totalmente utilizable por el procesador si la asignación de prioridad es factible para el conjunto y si un incremento en el tiempo de ejecución de cualquiera de las tareas en el conjunto harán que la asignación de prioridades se vuelva no factible. Para un algoritmo de \emph{scheduling} de prioridades fijas, el \emph{least upper bound} del factor de utilización es el mínimo de los factores de utilizacio4n de todos los conjuntos de tareas que utilizan totalmente el procesador. Para todas los conjuntos de tareas cuyo factor de utilización de procesador está por debajo de este límite, existe una asignación de prioridad fija que es factible. Debido que la asignación de prioridades \emph{rate monotonic} es óptima, el factor de utilización logrado por la asignación de prioridad \emph{rate-monotonic} para un conjunto de tareas es mayor o igual que el factor de utilización de cualquier otra asignación de prioridad para ese conjunto de tareas. Así, el \emph{least upper bound} a ser determinado es el ínfimo del factor de utilización correspondiente a la asignación de prioridad \emph{rate-monotonic} de todas los periódos de solicitudes posibles y de los tiempos de ejecución de las tareas. \underline{Teorema 3:} Para un conjunto de dos tareas con una asignación fija de prioridades, el \emph{least upper bound} del factor de utilización del procesador es $U = 2(2^{\frac{1}{2}} - 1)$. \underline{Teorema 4:} Para un conjunto de $m$ tareas con un orden de prioridad fijo, y la restricción que la proporción entre dos periódos de solicitud es menor que 2, el \emph{least upper bound} del factor de utilización del procesador es $U = m(2^{\frac{1}{m}} - 1)$. \underline{Teorema 5:} Para un conjunto de $m$ tareas con un orden de prioridad fijo, el \emph{least upper bound} de utilización de procesador es $U = m(2^{\frac{1}{m}} - 1)$.

\paragraph{\textnormal{\textbf{Relaxing the Utilization Bound}}}
En la sección anterior se muestra que el \emph{least upper bound} impuesto sobre la utilización del procesador por el requerimiento de servicio \emph{hard-time} garantizado puede acercarse a $\ln (2)$ para conjuntos grades de tareas. Es deseable encontrar forma de mejorar esta situación, debido a que los costos prácticos de cambiar entre tareas debe ser contado. Una de las formas más simples de hacer el costo del límite de utilización igual a 1 es hacer $\{T_m/T_i\} = 0$ para $i = 1,2,\dots,m - 1$. Dado que esto no se puede hacer siempre , una solución alternativa es poner en búfer la tarea $\tau_m$ y tal vez varias de las tareas de baja prioridad y relajar sus \emph{hard deadlines}.


\paragraph{\textnormal{\textbf{The Deadline Driven Scheduling Algorithm}}}
Usando este algoritmo, las prioridades son asignadas a las tareas de acuerdo a los \emph{deadlines} de sus solicitudes actuales. A una tarea se le asignará la prioridad más alta si el \emph{deadline} de su solicitud actual es el más cercano, y se le asignará la prioridad más baja si el \emph{deadline} de sus solicitud actual es el más lejano. En cualquier instante, la tarea con la prioridad más alta y con una solicitud aún no cumplida será ejecutada. Tal método de asignación de prioridades de las tareas un dinámico, en contraste con la asignación estática en donde las prioriedades de las tareas no cambian con el tiempo. \underline{Teorema 6:} Cuando el algoritmo de \emph{deadline driven scheduling} es usado para planificar un conjunto de tareas en un procesador, no hay tiempo de procesador inactivo antes de un \emph{overflow}. \underline{Teorema 7:} Dado un conjunto de $m$ tareas, el algoritmo de \emph{deadline driven scheduling} es factible si y solo si $$(C_1/T_1) + (C_2/T_2) + \dots + (C_m/T_m) \leq 1$$

\paragraph{\textnormal{\textbf{A Mixed Scheduling Algorithm}}}
Combinación de algoritmos de \emph{scheduling rate-monotonic} y de \emph{deadline driven}. A esta clase se les llama algoritmos de \emph{scheduling} mixtos. El estudio de estos algoritmos está motivada por la observación que el hardware de interrupciones de las computadores de ese momento actuaban como \emph{schedulers} de prioridad fija y no parecen ser compatibles con el \emph{scheduler} de hardware dinámico. Por otro lado, el costo de implementar un \emph{scheduler} en software para las tareas de ritmo más lento no incrementa significativamente si estas tareas son \emph{deadline driven} en lugar de tener una asignación de prioridad fija. Para ser específico, hacer las tareas $1, 2, \dots, k$ las $k$ tareas de periódos más cortos a ser planificadas/programadas de acuerdo a un algoritmo de \emph{scheduling} de prioridad fija \emph{rate-monotonic}, y dejar que las tareas restantes, las tareas $k + 1, k = 2, \dots, m$ sean planificadas/programadas de acuerdo a un algoritmo de \emph{scheduling deadline driven} cuando el procesador no está ocupado por las tareas $1, 2, \dots, k$.

Sea $a(t)$ una función no decreciente de $t$. Se dice que $a(i)$ es sublinear si para todo $t$ y todo $T$ $$a(T) \leq a(t + T) - a(t)$$ 
La función de disponibilidad de un procesador para un conjunto de tareas se define como el tiempo de procesador acumulado desde 0 a $t$ disponbile para este conjunto de tareas. Suponer que $k$ tareas han sido planificadas/programadas en un procesador por un algoritmo de \emph{scheduling} de prioridad fija. Denotar con $a_k(t)$ la función de disponibilidad del procesador para las tareas $k + 1, k + 2, \dots, m$. Claramente, $a_k(t)$ es una función no decreciente de $t$. Además, $a_k(t)$ puede ser vista como sublinear de acuerdo a: \underline{Teorema 8:} Si un conjunto de tareas están planificadas/programadas por el algoritmo de \emph{deadline driven scheduling} en un procesador cuya función de disponibilidad es sublinear, entonces no hay un periódo de tiempo de procesador inactivo para un \emph{overflow}. \underline{Teorema 9:} Una condición necesaria y suficiente para la factibilidad del algoritmo de \emph{deadline driven scheduling} con respecto a un procesador con función de disponibilidad $a_k(t)$ es: $$\lfloor t/T_{k+1} \rfloor C_{k+1} + \lfloor t/T_{k+2} \rfloor C_{k+2} + \dots + \lfloor t/T_m \rfloor C_m \leq a_k(t)$$ para toda $t$ que es múltiplos de $T_{k+1}$, o $T_{k+2}, \dots, $ o $T_m$.

\section{¿Cuál es el problema que plantea el \textit{paper}?}
El problema de \emph{multiprogram scheduling} es un solo procesador desde el punto de vista de las características propias de las funciones del programa que necesitan garantizar servicio.  

\section{¿Por qué el problema es interesante o importante?}
El uso de computadoras para control y monitoreo de procesos industriales se ha expandido mucho en años recientes, y probablemente se va a expandir aún más en el futuro. Usualmente, la computadora usada en tales aplicaciones es compartida entre un número de funciones de tiempo crítico y monitoreo y flujos de procesamiento por lotes no críticos en tiempo. Sin embargo, en otras instalaciones, no ningún trabajo \textbf{no} crítico en tiempo existe, y el uso eficiente de la computadora puede ser logrado solamente por medio de una planificación cuidadosa de las funciones críticas en tiempo y monitoreo. El último grupo se podría llamar \emph{``pure process control''} y provee la referencia para los análisis en \emph{combinatoric scheduling} presentados en el artículo.

\section{¿Qué otras soluciones se han intentado para resolver este problema?}
Mucha de la literatura disponible en multiprogramación tiene que ver con el análisis estadístico de sistemas comerciales de tiempo compartido. Otro subconjunto tiene que ver con aspectos más interesantes de planificación de una instalación de procesamiento por lotes o una instalación mixta de procesamiento por lotes en tiempo compartido, usualmente bajo una configuración multiprocesador. Manacher, deriva un algoritmo para la generación de planificación de tareas en un ambiente \emph{hard real-time}, pero sus resultados están restringuidos a una situación no realista en las que las tareas tienen solamente una solicitud a la vez, incluso cuando múltiples \emph{deadlines} son considerados. Lampson discute el problema de software \emph{scheduling} en términos generales y presenta un conjunto de procedimientos de multiprogramación en \textsc{Algol} que podrían ser implementadas o diseñadas dentro de un \emph{scheduler} de uso general. El texto de Martin, representa el rango de sistemas que son considerados de ``tiempo real'' y discute los problemas que se encuentran al intentar programarlos.

     
\section{¿Cuál es la solución propuesta por los autores?}
Dos algoritmos de \emph{scheduling} de tipo \emph{``pure process control''} se estudian. Ambos son orientados a prioridad y apropiamiento, lo que significa que el procesamiento de cualquier tarea es interrumpida por una solicitud de mayor prioridad. El primer algoritmo estudiado usa una asignación de prioridad fija y puede lograr utilización de procesador en el orden del 70\% o más. El segundo algoritmo de \emph{scheduling} puede lograr utilización total del procesador por medio de una asignación dinámica de prioridades. También se presenta una combinación de los dos algoritmos.

\section{¿Qué tan exitosa es esta solución?}
Un algoritmo de \emph{scheduling} que asigna prioridades a tareas en un relación monotónica con us tasas de solicitud se ha mostrado como óptimo entre la clase de todos los algoritmos de \emph{scheduling} de asignación fija. El \emph{least upper bound} del factor de utilización de procesador para este algoritmo está en el orden del 70\% para grandes conjuntos de tareas. El algoritmo de \emph{deadline} dinámico mostró ser globalmente óptimo y capaz de lograr utlización total de procesador. Una combinación de los dos algoritmos de \emph{scheduling} provee la mayoría de los beneficios de los algoritmos orientados a \emph{deadline}.   
